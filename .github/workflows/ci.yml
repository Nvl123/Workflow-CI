name: CI - MLflow

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  train_model:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: 3.9

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential curl

      - name: Check Python and pip versions
        run: |
          python --version
          pip --version

      - name: Install MLflow
        run: |
          pip install --upgrade pip
          pip install mlflow==2.10.2 pandas

      - name: Install dependencies
        run: |
          pip install -r MLProject/requirements.txt

      - name: Create directories
        run: |
          mkdir -p /tmp/mlruns
          mkdir -p /tmp/model_artifacts

      - name: Prepare MLProject files
        run: |
          ls -la MLProject/
          if [ -f "air_quality_cleaned.csv" ]; then
            cp air_quality_cleaned.csv MLProject/
          fi

      - name: Run MLflow project training
        run: |
          cd MLProject
          export MLFLOW_TRACKING_URI=file:/tmp/mlruns
          echo "Starting MLflow training..."
          echo "Current directory: $(pwd)"
          echo "Files in directory:"
          ls -la
          
          # Run the MLflow project
          mlflow run . -P fit_intercept=True --experiment-name "Air_Quality_Model" --env-manager=local
          
          echo "Training completed. Checking if model was saved..."
          
          # Verify model was saved by checking the latest run
          python3 -c "
          import mlflow
          import os
          mlflow.set_tracking_uri('file:/tmp/mlruns')
          
          # Get the latest run
          experiment = mlflow.get_experiment_by_name('Air_Quality_Model')
          if experiment:
              runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], max_results=1)
              if len(runs) > 0:
                  run_id = runs.iloc[0]['run_id']
                  print(f'Latest run ID: {run_id}')
                  
                  # Check if model artifact exists
                  artifacts_path = f'/tmp/mlruns/{experiment.experiment_id}/{run_id}/artifacts'
                  if os.path.exists(artifacts_path):
                      print(f'Artifacts directory exists: {artifacts_path}')
                      for root, dirs, files in os.walk(artifacts_path):
                          for file in files:
                              print(f'  {os.path.join(root, file)}')
                  else:
                      print(f'Artifacts directory not found: {artifacts_path}')
              else:
                  print('No runs found')
          else:
              print('Experiment not found')
          "
        env:
          MLFLOW_TRACKING_URI: file:/tmp/mlruns

      - name: Verify MLflow run and artifacts
        run: |
          export MLFLOW_TRACKING_URI=file:/tmp/mlruns
          echo "=== MLflow Verification ==="
          echo "Tracking URI: $MLFLOW_TRACKING_URI"
          echo "Experiment ID: ${{ env.experiment_id }}"
          echo "Run ID: ${{ env.MLFLOW_RUN_ID }}"
          
          echo "Listing experiments:"
          mlflow experiments search || echo "Failed to list experiments"
          
          echo "Listing runs:"
          mlflow runs list --experiment-name "Air_Quality_Model" | head -10 || echo "Failed to list runs"
          
          echo "Checking artifacts structure:"
          if [ -d "/tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }}" ]; then
            echo "Run directory exists"
            find /tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }} -type f | head -20
          else
            echo "Run directory not found"
            echo "Available runs in experiment:"
            ls -la /tmp/mlruns/${{ env.experiment_id }}/ || echo "Experiment directory not found"
          fi

      - name: Get latest MLflow run_id
        id: get_run_id
        run: |
          export MLFLOW_TRACKING_URI=file:/tmp/mlruns
          
          # Get experiment ID using a more reliable method
          experiment_id=$(python3 -c "
          import mlflow
          mlflow.set_tracking_uri('file:/tmp/mlruns')
          try:
              experiment = mlflow.get_experiment_by_name('Air_Quality_Model')
              if experiment:
                  print(experiment.experiment_id)
              else:
                  print('')
          except:
              print('')
          ")

          if [ -z "$experiment_id" ]; then
            echo "Experiment not found. Trying to create it..."
            experiment_id=$(python3 -c "
            import mlflow
            mlflow.set_tracking_uri('file:/tmp/mlruns')
            try:
                exp_id = mlflow.create_experiment('Air_Quality_Model')
                print(exp_id)
            except:
                # Experiment might already exist
                experiment = mlflow.get_experiment_by_name('Air_Quality_Model')
                if experiment:
                    print(experiment.experiment_id)
                else:
                    print('')
            ")
          fi

          if [ -z "$experiment_id" ]; then
            echo "Could not get or create experiment"
            exit 1
          fi

          echo "experiment_id=$experiment_id" >> $GITHUB_ENV
          echo "Found experiment_id: $experiment_id"

          # Get the latest run ID
          run_id=$(python3 -c "
          import mlflow
          mlflow.set_tracking_uri('file:/tmp/mlruns')
          try:
              runs = mlflow.search_runs(experiment_ids=['$experiment_id'], max_results=1)
              if len(runs) > 0:
                  print(runs.iloc[0]['run_id'])
              else:
                  print('')
          except:
              print('')
          ")

          if [ -z "$run_id" ]; then
            echo "No runs found in experiment"
            exit 1
          fi

          echo "MLFLOW_RUN_ID=$run_id" >> $GITHUB_ENV
          echo "Found run_id: $run_id"

      - name: Upload MLflow artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-artifacts
          path: /tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }}/artifacts
          retention-days: 30
        continue-on-error: true



      - name: Check Docker Hub secrets
        id: check_secrets
        run: |
          if [ -n "${{ secrets.DOCKER_USERNAME }}" ] && [ -n "${{ secrets.DOCKER_PASSWORD }}" ]; then
            echo "docker_secrets_available=true" >> $GITHUB_OUTPUT
          else
            echo "docker_secrets_available=false" >> $GITHUB_OUTPUT
            echo "Docker Hub secrets not available, skipping Docker operations"
          fi

      - name: Build and Push Docker image
        if: steps.check_secrets.outputs.docker_secrets_available == 'true'
        run: |
          export MLFLOW_TRACKING_URI=file:/tmp/mlruns
          echo "Building Docker image for MLflow model..."
          
          # Check if model artifacts exist
          MODEL_PATH="/tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }}/artifacts/model"
          if [ -d "$MODEL_PATH" ]; then
            echo "Model artifacts found at: $MODEL_PATH"
            
            # Create build directory and copy model
            mkdir -p docker_build/model
            cp -r "$MODEL_PATH"/* docker_build/model/
            
            # Create Dockerfile using echo instead of heredoc
            cd docker_build
            echo "FROM python:3.9-slim" > Dockerfile
            echo "WORKDIR /app" >> Dockerfile
            echo "RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*" >> Dockerfile
            echo "RUN pip install mlflow==2.10.2 pandas scikit-learn" >> Dockerfile
            echo "COPY model /app/model" >> Dockerfile
            echo "EXPOSE 5000" >> Dockerfile
            echo 'CMD ["mlflow", "models", "serve", "-m", "/app/model", "-h", "0.0.0.0", "-p", "5000", "--no-conda"]' >> Dockerfile
            
            # Build Docker image
            if docker build -t air_quality_model .; then
              echo "Docker image built successfully"
              
              # Login to Docker Hub
              echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin
              
              # Tag and push
              docker tag air_quality_model ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest
              docker push ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest
              echo "Docker image pushed to ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest"
              
              # Logout
              docker logout
            else
              echo "Docker build failed"
              exit 1
            fi
            
            cd ..
          else
            echo "Model artifacts not found - skipping Docker build"
            exit 1
          fi
        continue-on-error: true

      - name: Training Summary
        run: |
          echo "=== MLflow Training Summary ==="
          echo "Experiment ID: ${{ env.experiment_id }}"
          echo "Run ID: ${{ env.MLFLOW_RUN_ID }}"
          echo "Tracking URI: file:/tmp/mlruns"
          echo "Artifacts uploaded to GitHub Actions"
          if [ -n "${{ secrets.DOCKER_USERNAME }}" ]; then
            echo "Docker image: ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest"
          fi
          echo "Model training and deployment completed successfully"
