name: CI - MLFlow Simple

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  train_model:
    runs-on: ubuntu-latest

    steps:
    # Checkout repository
    - name: Checkout repo
      uses: actions/checkout@v4

    # Setup Python environment
    - name: Set up Python 3.9
      uses: actions/setup-python@v5
      with:
        python-version: 3.9

    # Install system dependencies
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential

    # Verify Python and pip versions
    - name: Check Python and pip versions
      run: |
        python --version
        pip --version

    # Install dependencies
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r MLProject/requirements.txt

    # Create directories for artifacts
    - name: Create directories
      run: |
        mkdir -p /tmp/mlruns
        mkdir -p /tmp/model_artifacts

    # Prepare dataset
    - name: Prepare dataset
      run: |
        # Check if dataset exists and copy to MLProject if needed
        if [ -f "air_quality_cleaned.csv" ]; then
          cp air_quality_cleaned.csv MLProject/
          echo "Dataset copied to MLProject directory"
        fi
        
        # List files in MLProject directory
        echo "Files in MLProject directory:"
        ls -la MLProject/

    # Run training script directly (more reliable than MLflow project)
    - name: Run training script
      run: |
        cd MLProject
        export MLFLOW_TRACKING_URI=file:/tmp/mlruns
        python train.py --fit_intercept True
      env:
        MLFLOW_TRACKING_URI: file:/tmp/mlruns

    # Verify MLflow run completion
    - name: Verify MLflow run
      run: |
        export MLFLOW_TRACKING_URI=file:/tmp/mlruns
        echo "Listing experiments:"
        mlflow experiments list
        echo ""
        echo "Listing runs for Air_Quality_Model experiment:"
        mlflow runs list --experiment-name "Air_Quality_Model" --max-results 5

    # Get latest MLflow run_id
    - name: Get latest MLflow run_id
      id: get_run_id
      run: |
        export MLFLOW_TRACKING_URI=file:/tmp/mlruns
        
        # Get experiment ID using MLflow CLI
        experiment_id=$(mlflow experiments list | grep "Air_Quality_Model" | awk '{print $1}' | head -1)
        
        if [ -z "$experiment_id" ]; then
          echo "Air_Quality_Model experiment not found, trying default experiment"
          experiment_id="0"
        fi
        
        echo "experiment_id=$experiment_id" >> $GITHUB_ENV
        echo "Using experiment_id: $experiment_id"
        
        # Get latest run ID
        run_id=$(mlflow runs list --experiment-id $experiment_id | tail -n +2 | head -1 | awk '{print $2}')
        
        if [ -z "$run_id" ]; then
          echo "No runs found in experiment $experiment_id"
          # List directory structure for debugging
          echo "MLruns directory structure:"
          find /tmp/mlruns -type f -name "*.yaml" | head -10
          exit 1
        fi
        
        echo "MLFLOW_RUN_ID=$run_id" >> $GITHUB_ENV
        echo "Found run_id: $run_id"

    # Upload MLflow artifacts
    - name: Upload MLflow artifacts
      uses: actions/upload-artifact@v4
      with:
        name: mlflow-artifacts
        path: /tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }}/artifacts
        retention-days: 30
      continue-on-error: true

    # Optional: Build Docker image using MLflow
    - name: Build Docker image for MLflow model
      run: |
        export MLFLOW_TRACKING_URI=file:/tmp/mlruns
        echo "Attempting to build Docker image..."
        
        # Try to build Docker image
        if mlflow models build-docker \
          -m "runs:/${{ env.MLFLOW_RUN_ID }}/model" \
          -n air_quality_model; then
          echo "Docker image built successfully"
          echo "DOCKER_BUILD_SUCCESS=true" >> $GITHUB_ENV
        else
          echo "Docker build failed, but continuing..."
          echo "DOCKER_BUILD_SUCCESS=false" >> $GITHUB_ENV
        fi
      continue-on-error: true

    # Docker Hub operations (only if build succeeded and secrets available)
    - name: Check Docker Hub secrets
      id: check_secrets
      run: |
        if [ -n "${{ secrets.DOCKER_USERNAME }}" ] && [ -n "${{ secrets.DOCKER_PASSWORD }}" ] && [ "${{ env.DOCKER_BUILD_SUCCESS }}" == "true" ]; then
          echo "docker_push_ready=true" >> $GITHUB_OUTPUT
        else
          echo "docker_push_ready=false" >> $GITHUB_OUTPUT
          echo "Skipping Docker push - missing secrets or build failed"
        fi

    - name: Log in to Docker Hub
      if: steps.check_secrets.outputs.docker_push_ready == 'true'
      run: echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin

    - name: Tag and push Docker image
      if: steps.check_secrets.outputs.docker_push_ready == 'true'
      run: |
        docker tag air_quality_model ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest
        docker tag air_quality_model ${{ secrets.DOCKER_USERNAME }}/air_quality_model:${{ env.MLFLOW_RUN_ID }}
        docker push ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest
        docker push ${{ secrets.DOCKER_USERNAME }}/air_quality_model:${{ env.MLFLOW_RUN_ID }}
        echo "Docker images pushed successfully"

    - name: Log out from Docker Hub
      if: steps.check_secrets.outputs.docker_push_ready == 'true'
      run: docker logout

    # Training Summary
    - name: Training Summary
      run: |
        echo "=== MLflow Training Summary ==="
        echo "Experiment: Air_Quality_Model"
        echo "Experiment ID: ${{ env.experiment_id }}"
        echo "Run ID: ${{ env.MLFLOW_RUN_ID }}"
        echo "Tracking URI: file:/tmp/mlruns"
        echo "Artifacts uploaded to GitHub Actions"
        
        if [ "${{ env.DOCKER_BUILD_SUCCESS }}" == "true" ] && [ -n "${{ secrets.DOCKER_USERNAME }}" ]; then
          echo "Docker images:"
          echo "  - ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest"
          echo "  - ${{ secrets.DOCKER_USERNAME }}/air_quality_model:${{ env.MLFLOW_RUN_ID }}"
        fi
        
        echo ""
        echo "=== Model Metrics ==="
        export MLFLOW_TRACKING_URI=file:/tmp/mlruns
        mlflow runs describe --run-id ${{ env.MLFLOW_RUN_ID }} || echo "Could not retrieve run details"
