name: CI - MLflow

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  train_model:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: 3.9

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential curl

      - name: Check Python and pip versions
        run: |
          python --version
          pip --version

      - name: Install MLflow
        run: |
          pip install --upgrade pip
          pip install mlflow==2.10.2 pandas

      - name: Install dependencies
        run: |
          pip install -r MLProject/requirements.txt

      - name: Create directories
        run: |
          mkdir -p /tmp/mlruns
          mkdir -p /tmp/model_artifacts

      - name: Prepare MLProject files
        run: |
          ls -la MLProject/
          if [ -f "air_quality_cleaned.csv" ]; then
            cp air_quality_cleaned.csv MLProject/
          fi

      - name: Run MLflow project training
        run: |
          cd MLProject
          export MLFLOW_TRACKING_URI=file:/tmp/mlruns
          echo "Starting MLflow training..."
          echo "Current directory: $(pwd)"
          echo "Files in directory:"
          ls -la
          
          # Run the MLflow project
          mlflow run . -P fit_intercept=True --experiment-name "Air_Quality_Model" --env-manager=local
          
          echo "Training completed. Checking if model was saved..."
          
          # Verify model was saved by checking the latest run
          python3 -c "
          import mlflow
          import os
          mlflow.set_tracking_uri('file:/tmp/mlruns')
          
          # Get the latest run
          experiment = mlflow.get_experiment_by_name('Air_Quality_Model')
          if experiment:
              runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], max_results=1)
              if len(runs) > 0:
                  run_id = runs.iloc[0]['run_id']
                  print(f'Latest run ID: {run_id}')
                  
                  # Check if model artifact exists
                  artifacts_path = f'/tmp/mlruns/{experiment.experiment_id}/{run_id}/artifacts'
                  if os.path.exists(artifacts_path):
                      print(f'Artifacts directory exists: {artifacts_path}')
                      for root, dirs, files in os.walk(artifacts_path):
                          for file in files:
                              print(f'  {os.path.join(root, file)}')
                  else:
                      print(f'Artifacts directory not found: {artifacts_path}')
              else:
                  print('No runs found')
          else:
              print('Experiment not found')
          "
        env:
          MLFLOW_TRACKING_URI: file:/tmp/mlruns

      - name: Verify MLflow run and artifacts
        run: |
          export MLFLOW_TRACKING_URI=file:/tmp/mlruns
          echo "=== MLflow Verification ==="
          echo "Tracking URI: $MLFLOW_TRACKING_URI"
          echo "Experiment ID: ${{ env.experiment_id }}"
          echo "Run ID: ${{ env.MLFLOW_RUN_ID }}"
          
          echo "Listing experiments:"
          mlflow experiments search || echo "Failed to list experiments"
          
          echo "Listing runs:"
          mlflow runs list --experiment-name "Air_Quality_Model" | head -10 || echo "Failed to list runs"
          
          echo "Checking artifacts structure:"
          if [ -d "/tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }}" ]; then
            echo "Run directory exists"
            find /tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }} -type f | head -20
          else
            echo "Run directory not found"
            echo "Available runs in experiment:"
            ls -la /tmp/mlruns/${{ env.experiment_id }}/ || echo "Experiment directory not found"
          fi

      - name: Get latest MLflow run_id
        id: get_run_id
        run: |
          export MLFLOW_TRACKING_URI=file:/tmp/mlruns
          
          # Get experiment ID using a more reliable method
          experiment_id=$(python3 -c "
          import mlflow
          mlflow.set_tracking_uri('file:/tmp/mlruns')
          try:
              experiment = mlflow.get_experiment_by_name('Air_Quality_Model')
              if experiment:
                  print(experiment.experiment_id)
              else:
                  print('')
          except:
              print('')
          ")

          if [ -z "$experiment_id" ]; then
            echo "Experiment not found. Trying to create it..."
            experiment_id=$(python3 -c "
            import mlflow
            mlflow.set_tracking_uri('file:/tmp/mlruns')
            try:
                exp_id = mlflow.create_experiment('Air_Quality_Model')
                print(exp_id)
            except:
                # Experiment might already exist
                experiment = mlflow.get_experiment_by_name('Air_Quality_Model')
                if experiment:
                    print(experiment.experiment_id)
                else:
                    print('')
            ")
          fi

          if [ -z "$experiment_id" ]; then
            echo "Could not get or create experiment"
            exit 1
          fi

          echo "experiment_id=$experiment_id" >> $GITHUB_ENV
          echo "Found experiment_id: $experiment_id"

          # Get the latest run ID
          run_id=$(python3 -c "
          import mlflow
          mlflow.set_tracking_uri('file:/tmp/mlruns')
          try:
              runs = mlflow.search_runs(experiment_ids=['$experiment_id'], max_results=1)
              if len(runs) > 0:
                  print(runs.iloc[0]['run_id'])
              else:
                  print('')
          except:
              print('')
          ")

          if [ -z "$run_id" ]; then
            echo "No runs found in experiment"
            exit 1
          fi

          echo "MLFLOW_RUN_ID=$run_id" >> $GITHUB_ENV
          echo "Found run_id: $run_id"

      - name: Upload MLflow artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-artifacts
          path: /tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }}/artifacts
          retention-days: 30
        continue-on-error: true

      - name: Build Docker image for MLflow model
        run: |
          export MLFLOW_TRACKING_URI=file:/tmp/mlruns
          echo "Attempting to build Docker image..."
          echo "Run ID: ${{ env.MLFLOW_RUN_ID }}"
          echo "Experiment ID: ${{ env.experiment_id }}"
          
          # Check if model artifacts exist
          MODEL_PATH="/tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }}/artifacts/model"
          if [ -d "$MODEL_PATH" ]; then
            echo "Model artifacts found at: $MODEL_PATH"
            echo "Model artifacts contents:"
            ls -la "$MODEL_PATH"
            
            # Create a build directory and copy model artifacts
            mkdir -p docker_build/model
            cp -r "$MODEL_PATH"/* docker_build/model/
            
            # Create a simple Dockerfile in the build directory
            cat > docker_build/Dockerfile << 'EOF'
FROM python:3.9-slim

WORKDIR /app

# Install system dependencies and Python packages
RUN apt-get update && apt-get install -y --no-install-recommends curl && rm -rf /var/lib/apt/lists/* && pip install --no-cache-dir mlflow==2.10.2 pandas scikit-learn

# Copy model artifacts (from build context)
COPY model /app/model

# Expose port
EXPOSE 5000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 CMD curl -f http://localhost:5000/health || exit 1

# Run MLflow model server
CMD ["mlflow", "models", "serve", "-m", "/app/model", "-h", "0.0.0.0", "-p", "5000", "--no-conda"]
EOF
            
            # Build Docker image from the build directory
            cd docker_build
            echo "Building Docker image from: $(pwd)"
            echo "Build context contents:"
            ls -la
            
            if docker build -t air_quality_model .; then
              echo "Docker image built successfully using alternative method"
              
              # Verify the image was created
              echo "Verifying Docker image:"
              docker images | grep air_quality_model
              
              # Simple test - just check if container can start
              echo "Testing if Docker container can start..."
              if timeout 30 docker run --rm air_quality_model python -c "import mlflow; print('MLflow import successful')"; then
                echo "Docker image test passed - MLflow is working in container"
              else
                echo "Docker image test warning - there might be issues with the container"
              fi
              
            else
              echo "Alternative Docker build also failed"
              exit 1
            fi
            
            cd ..
            
          else
            echo "Model artifacts not found at: $MODEL_PATH"
            echo "Checking available artifacts..."
            ARTIFACTS_DIR="/tmp/mlruns/${{ env.experiment_id }}/${{ env.MLFLOW_RUN_ID }}/artifacts"
            if [ -d "$ARTIFACTS_DIR" ]; then
              echo "Artifacts directory exists, contents:"
              find "$ARTIFACTS_DIR" -type f
            else
              echo "No artifacts directory found"
            fi
            echo "Skipping Docker build - no model artifacts"
            exit 1
          fi
        continue-on-error: true

      - name: Check Docker Hub secrets
        id: check_secrets
        run: |
          if [ -n "${{ secrets.DOCKER_USERNAME }}" ] && [ -n "${{ secrets.DOCKER_PASSWORD }}" ]; then
            echo "docker_secrets_available=true" >> $GITHUB_OUTPUT
          else
            echo "docker_secrets_available=false" >> $GITHUB_OUTPUT
            echo "Docker Hub secrets not available, skipping Docker operations"
          fi

      - name: Log in to Docker Hub
        if: steps.check_secrets.outputs.docker_secrets_available == 'true'
        run: echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin

      - name: Tag and push Docker image
        if: steps.check_secrets.outputs.docker_secrets_available == 'true'
        run: |
          echo "Checking available Docker images..."
          docker images
          
          if docker images | grep -q air_quality_model; then
            echo "Docker image found, proceeding with tag and push..."
            docker tag air_quality_model ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest
            
            if docker push ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest; then
              echo "Docker image pushed successfully to ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest"
            else
              echo "Failed to push Docker image"
              exit 1
            fi
          else
            echo "Docker image 'air_quality_model' not found"
            echo "Available images:"
            docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}"
            echo "Skipping push"
          fi
        continue-on-error: true

      - name: Log out from Docker Hub
        if: steps.check_secrets.outputs.docker_secrets_available == 'true'
        run: docker logout

      - name: Training Summary
        run: |
          echo "=== MLflow Training Summary ==="
          echo "Experiment ID: ${{ env.experiment_id }}"
          echo "Run ID: ${{ env.MLFLOW_RUN_ID }}"
          echo "Tracking URI: file:/tmp/mlruns"
          echo "Artifacts uploaded to GitHub Actions"
          if [ -n "${{ secrets.DOCKER_USERNAME }}" ]; then
            echo "Docker image: ${{ secrets.DOCKER_USERNAME }}/air_quality_model:latest"
          fi
